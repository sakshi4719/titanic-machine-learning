{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3136,"databundleVersionId":26502,"sourceType":"competition"}],"dockerImageVersionId":30804,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-14T10:03:24.928819Z","iopub.execute_input":"2024-12-14T10:03:24.929925Z","iopub.status.idle":"2024-12-14T10:03:24.939522Z","shell.execute_reply.started":"2024-12-14T10:03:24.929866Z","shell.execute_reply":"2024-12-14T10:03:24.938214Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T10:03:24.942009Z","iopub.execute_input":"2024-12-14T10:03:24.942486Z","iopub.status.idle":"2024-12-14T10:03:24.953672Z","shell.execute_reply.started":"2024-12-14T10:03:24.942434Z","shell.execute_reply":"2024-12-14T10:03:24.952690Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_path = '/kaggle/input/titanic/train.csv'\ntrain_data = pd.read_csv(train_path)\ntest_path = '/kaggle/input/titanic/test.csv'\ntest_data = pd.read_csv(test_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T10:03:24.955030Z","iopub.execute_input":"2024-12-14T10:03:24.955358Z","iopub.status.idle":"2024-12-14T10:03:24.976761Z","shell.execute_reply.started":"2024-12-14T10:03:24.955326Z","shell.execute_reply":"2024-12-14T10:03:24.975726Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_data['Sex'] = train_data['Sex'].map({'male': 0, 'female': 1})\ntest_data['Sex'] = test_data['Sex'].map({'male': 0, 'female': 1})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T10:03:24.978073Z","iopub.execute_input":"2024-12-14T10:03:24.978385Z","iopub.status.idle":"2024-12-14T10:03:24.987224Z","shell.execute_reply.started":"2024-12-14T10:03:24.978353Z","shell.execute_reply":"2024-12-14T10:03:24.986040Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_data.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T10:03:24.990007Z","iopub.execute_input":"2024-12-14T10:03:24.991102Z","iopub.status.idle":"2024-12-14T10:03:25.010291Z","shell.execute_reply.started":"2024-12-14T10:03:24.991048Z","shell.execute_reply":"2024-12-14T10:03:25.009107Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_data.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T10:03:25.011631Z","iopub.execute_input":"2024-12-14T10:03:25.012107Z","iopub.status.idle":"2024-12-14T10:03:25.028964Z","shell.execute_reply.started":"2024-12-14T10:03:25.012071Z","shell.execute_reply":"2024-12-14T10:03:25.027774Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_data.describe()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T10:03:25.030663Z","iopub.execute_input":"2024-12-14T10:03:25.031489Z","iopub.status.idle":"2024-12-14T10:03:25.071617Z","shell.execute_reply.started":"2024-12-14T10:03:25.031451Z","shell.execute_reply":"2024-12-14T10:03:25.070514Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_data.describe()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T10:03:25.073519Z","iopub.execute_input":"2024-12-14T10:03:25.073856Z","iopub.status.idle":"2024-12-14T10:03:25.106498Z","shell.execute_reply.started":"2024-12-14T10:03:25.073823Z","shell.execute_reply":"2024-12-14T10:03:25.105390Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#test_data['Fare'] = test_data['Fare'].fillna(14.454200)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T10:03:25.115377Z","iopub.execute_input":"2024-12-14T10:03:25.115769Z","iopub.status.idle":"2024-12-14T10:03:25.120333Z","shell.execute_reply.started":"2024-12-14T10:03:25.115737Z","shell.execute_reply":"2024-12-14T10:03:25.119214Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"from sklearn.linear_model import LinearRegression\nfrom sklearn.preprocessing import LabelEncoder\n\n# Encode 'Sex' column to numeric\nlabel_encoder = LabelEncoder()\ntrain_data['Sex'] = label_encoder.fit_transform(train_data['Sex'])\ntest_data['Sex'] = label_encoder.transform(test_data['Sex'])  # Apply the same encoding to test_data\n\n# Separate rows with and without missing Age values in train_data\nage_train = train_data[train_data['Age'].notna()]\nage_test = train_data[train_data['Age'].isna()]\n\n# Features to predict Age\nfeatures_age = ['Pclass', 'Sex', 'Parch', 'Fare', 'SibSp']\n\n# Prepare the training data for age imputation\nX_train = age_train[features_age]\ny_train = age_train['Age']\n\n# Train a linear regression model\nmodel = LinearRegression()\nmodel.fit(X_train, y_train)\n\n# Predict missing Age values in train_data\nage_test['Age'] = model.predict(age_test[features_age])\n\n# Combine the datasets back for train_data\ntrain_data.loc[train_data['Age'].isna(), 'Age'] = age_test['Age']\n\n# Confirm there are no missing values in Age in train_data\nprint(f\"Missing Age values in train_data after filling: {train_data['Age'].isna().sum()}\")\n\n# Now, apply the same method to test_data (predict missing Age values)\n# For test_data, we don't have the target 'Age' column, so we just predict for the missing values\ntest_data_age_missing = test_data[test_data['Age'].isna()]\n\n# Predict missing Age values in test_data\ntest_data_age_missing['Age'] = model.predict(test_data_age_missing[features_age])\n\n# Combine the datasets back for test_data\ntest_data.loc[test_data['Age'].isna(), 'Age'] = test_data_age_missing['Age']\n\n# Confirm there are no missing values in Age in test_data\nprint(f\"Missing Age values in test_data after filling: {test_data['Age'].isna().sum()}\")\n","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"missing_stats = test_data.isna().sum()\nprint(missing_stats[missing_stats > 0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T10:03:25.122850Z","iopub.execute_input":"2024-12-14T10:03:25.123331Z","iopub.status.idle":"2024-12-14T10:03:25.135913Z","shell.execute_reply.started":"2024-12-14T10:03:25.123284Z","shell.execute_reply":"2024-12-14T10:03:25.134795Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"missing_stats = train_data.isna().sum()\nprint(missing_stats[missing_stats > 0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T10:03:25.137238Z","iopub.execute_input":"2024-12-14T10:03:25.137674Z","iopub.status.idle":"2024-12-14T10:03:25.151890Z","shell.execute_reply.started":"2024-12-14T10:03:25.137625Z","shell.execute_reply":"2024-12-14T10:03:25.150729Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# from sklearn.preprocessing import OneHotEncoder\n# import pandas as pd\n\n# # Assuming train_data and test_data are your DataFrames\n\n# # Initialize OneHotEncoder, without dropping any category (keep all 3 categories)\n# encoder = OneHotEncoder(drop=None, sparse=False)\n\n# # Apply OneHotEncoder to the 'Embarked' column for both train and test data\n# train_embarked_encoded = pd.DataFrame(encoder.fit_transform(train_data[['Embarked']]))\n# test_embarked_encoded = pd.DataFrame(encoder.transform(test_data[['Embarked']]))\n\n# # Set proper column names for the encoded columns\n# train_embarked_encoded.columns = encoder.get_feature_names_out(['Embarked'])\n# test_embarked_encoded.columns = encoder.get_feature_names_out(['Embarked'])\n\n# # Now, drop the old 'Embarked' column and join the encoded columns\n# train_data = train_data.drop('Embarked', axis=1).join(train_embarked_encoded)\n# test_data = test_data.drop('Embarked', axis=1).join(test_embarked_encoded)\n\n# # Print the updated train and test data\n# print(train_data.head())\n# print(test_data.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T10:03:25.153261Z","iopub.execute_input":"2024-12-14T10:03:25.153576Z","iopub.status.idle":"2024-12-14T10:03:25.164833Z","shell.execute_reply.started":"2024-12-14T10:03:25.153533Z","shell.execute_reply":"2024-12-14T10:03:25.163792Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"features = ['Sex', \"Pclass\", 'Age', 'Fare', 'Parch', 'Embarked']\n# not sure how important EMBARKED IS","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T10:03:25.167737Z","iopub.execute_input":"2024-12-14T10:03:25.168214Z","iopub.status.idle":"2024-12-14T10:03:25.183205Z","shell.execute_reply.started":"2024-12-14T10:03:25.168165Z","shell.execute_reply":"2024-12-14T10:03:25.182030Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_train = train_data[features]\nX_test = test_data[features]\n\ny = train_data.Survived","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T10:03:25.184452Z","iopub.execute_input":"2024-12-14T10:03:25.184808Z","iopub.status.idle":"2024-12-14T10:03:25.201317Z","shell.execute_reply.started":"2024-12-14T10:03:25.184774Z","shell.execute_reply":"2024-12-14T10:03:25.200300Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define the pipeline and preprocessing steps\nnumerical_transformer = SimpleImputer(strategy='mean')  # Replace NaN with mean for numerical columns\n\ncategorical_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='most_frequent')),  # Replace NaN with most frequent for categorical columns\n    ('onehot', OneHotEncoder(handle_unknown='ignore'))  # One-hot encoding for categorical variables\n])\n\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', numerical_transformer, ['Age', 'Fare']),  # Replace with numerical column names\n        ('cat', categorical_transformer, ['Embarked'])   # Replace with categorical column names\n    ])\n\nmy_pipeline = Pipeline(steps=[\n    ('preprocessor', preprocessor),\n    ('model', RandomForestRegressor(random_state=1))  # Random forest model\n])\n\n# Apply the pipeline for fitting and predictions\nmy_pipeline.fit(X_train, y)  # Fit the pipeline on training data\npredictions = my_pipeline.predict(X_test)  # Predict on test data\n\n# Convert predictions to binary format (e.g., 0 or 1 for Survived)\nrf_val_final = (predictions > 0.5).astype(int)  # Adjust threshold if needed\n\n# Save the predictions to a CSV file\noutput = pd.DataFrame({\n    'PassengerId': test_data['PassengerId'],  # Use PassengerId from the test dataset\n    'Survived': rf_val_final  # Add predictions\n})\n\noutput.to_csv('titanic_submission.csv', index=False)  # Save to CSV for submission\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T10:03:25.202671Z","iopub.execute_input":"2024-12-14T10:03:25.203033Z","iopub.status.idle":"2024-12-14T10:03:25.478197Z","shell.execute_reply.started":"2024-12-14T10:03:25.202963Z","shell.execute_reply":"2024-12-14T10:03:25.477049Z"}},"outputs":[],"execution_count":null}]}